{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE3cHt1w_0AX"
   },
   "source": [
    "# BUILDING A TFRECORDS DATABASE\n",
    "\n",
    "In this notebook, a TFRecords database is built from the MRI dataset that has already been organized in folders, according to the possible labels:\n",
    "\n",
    "* CN\n",
    "* MCI\n",
    "* AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fiiMO_gt_Y3z",
    "outputId": "c57d7313-292e-493e-c4d5-4be315c0613a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SimpleITK\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/6b/85df5eb3a8059b23a53a9f224476e75473f9bcc0a8583ed1a9c34619f372/SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4MB)\n",
      "\u001b[K     |████████████████████████████████| 47.4MB 63kB/s \n",
      "\u001b[?25hInstalling collected packages: SimpleITK\n",
      "Successfully installed SimpleITK-2.0.2\n",
      "Collecting dltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/55/bc7d72866c61f34f298e494d01c7c69eb26e8af711f5a2694c6bb9dceaca/dltk-0.2.1.tar.gz (294kB)\n",
      "\u001b[K     |████████████████████████████████| 296kB 5.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dltk) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from dltk) (1.4.1)\n",
      "Requirement already satisfied: pandas>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from dltk) (1.1.5)\n",
      "Requirement already satisfied: matplotlib>=1.5.3 in /usr/local/lib/python3.7/dist-packages (from dltk) (3.2.2)\n",
      "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from dltk) (0.16.0)\n",
      "Requirement already satisfied: xlrd>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dltk) (1.1.0)\n",
      "Requirement already satisfied: scikit-image>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from dltk) (0.16.2)\n",
      "Requirement already satisfied: SimpleITK>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from dltk) (2.0.2)\n",
      "Requirement already satisfied: jupyter>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from dltk) (1.0.0)\n",
      "Collecting argparse\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.0->dltk) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.0->dltk) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.3->dltk) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.3->dltk) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.3->dltk) (1.3.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.13.0->dltk) (2.4.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.13.0->dltk) (7.1.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.13.0->dltk) (2.5.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.13.0->dltk) (1.1.1)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0.0->dltk) (5.3.1)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0.0->dltk) (4.10.1)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0.0->dltk) (7.6.3)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0.0->dltk) (5.2.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0.0->dltk) (5.6.1)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0.0->dltk) (5.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19.0->dltk) (1.15.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.13.0->dltk) (4.4.2)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->dltk) (0.10.1)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->dltk) (5.1.3)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->dltk) (5.3.5)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->dltk) (5.0.5)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->dltk) (4.7.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->dltk) (1.5.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->dltk) (0.2.0)\n",
      "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->dltk) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->dltk) (2.11.3)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1.0.0->dltk) (5.5.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter>=1.0.0->dltk) (3.5.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter>=1.0.0->dltk) (1.0.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter>=1.0.0->dltk) (1.0.18)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter>=1.0.0->dltk) (2.6.1)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0.0->dltk) (3.3.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0.0->dltk) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0.0->dltk) (1.4.3)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0.0->dltk) (0.5.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0.0->dltk) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0.0->dltk) (0.8.4)\n",
      "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter>=1.0.0->dltk) (22.1.0)\n",
      "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter>=1.0.0->dltk) (1.9.0)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0.0->dltk) (0.7.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter>=1.0.0->dltk) (2.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter>=1.0.0->dltk) (2.0.1)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter>=1.0.0->dltk) (0.8.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter>=1.0.0->dltk) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter>=1.0.0->dltk) (57.0.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter>=1.0.0->dltk) (4.8.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter>=1.0.0->dltk) (0.2.5)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter>=1.0.0->dltk) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter>=1.0.0->dltk) (20.9)\n",
      "Building wheels for collected packages: dltk\n",
      "  Building wheel for dltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for dltk: filename=dltk-0.2.1-py2.py3-none-any.whl size=37271 sha256=9e0f77eba4910741c66c52ee27d9fa21c8ee5a8f5bbdb2559f16c0b871f8bfbd\n",
      "  Stored in directory: /root/.cache/pip/wheels/9d/72/c6/8d739d38edc23d5f5e58aeaeff23df0236bb2449edccf93898\n",
      "Successfully built dltk\n",
      "Installing collected packages: argparse, dltk\n",
      "Successfully installed argparse-1.4.0 dltk-0.2.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "argparse"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "! pip install SimpleITK\n",
    "! pip install dltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HM6Dfs0MADhS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from dltk.io import preprocessing\n",
    "import os\n",
    "import collections\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kR2aDixAejJ"
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "  \n",
    "def _bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtZV7f6oC2mw"
   },
   "outputs": [],
   "source": [
    "##basic raw databases with skull stripped images\n",
    "DB_SS_PATH = '/content/drive/MyDrive/SKULL_STRIPPED/'\n",
    "\n",
    "# the data description file\n",
    "DESCRIPTION_FILE = '/content/drive/MyDrive/ADNI1_Complete_1Yr_1.5T_6_11_2021.csv'\n",
    "\n",
    "# data subfolders (labels)\n",
    "CLASS_SUBFOLDERS = ['MCI/', 'AD/', 'CN/']\n",
    "BINARY_CLASS_SUBFOLDERS = ['AD/', 'CN/']\n",
    "\n",
    "# 3D supervised TFRecords database\n",
    "DB_TF_3D_PATH = '/content/drive/MyDrive/TF_RECORDS/TF_RECORDS_3D/'\n",
    "\n",
    "##tfrecords files\n",
    "TFREC_3D_SS_TRAIN = 'train.3D.skull_stripped.tfrecords'\n",
    "TFREC_3D_SS_TEST = 'test.3D.skull_stripped.tfrecords'\n",
    "TFREC_3D_SS_VAL = 'validation.3D.skull_stripped.tfrecords'\n",
    "\n",
    "# 2D supervised TFRecords database\n",
    "DB_TF_2D_PATH = '/content/drive/MyDrive/TF_RECORDS/TF_RECORDS_2D/'\n",
    "\n",
    "TFREC_2D_SS_TRAIN = 'train.2D.skull_stripped.tfrecords'\n",
    "TFREC_2D_BIN_TRAIN = 'train.2D.binary.tfrecords'\n",
    "TFREC_2D_SS_TEST = 'test.2D.skull_stripped.tfrecords'\n",
    "TFREC_2D_BIN_TEST = 'test.2D.binary.tfrecords'\n",
    "TFREC_2D_SS_VAL = 'validation.2D.skull_stripped.tfrecords'\n",
    "TFREC_2D_BIN_VAL = 'validation.2D.binary.tfrecords'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x00LAWKoLwH3"
   },
   "source": [
    "Identifiers for the three different classes are needed. Also save the shape of the images, in case that information is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KouLS9x3LT_3"
   },
   "outputs": [],
   "source": [
    "# label mapping\n",
    "LABELS = {'CN': 0, 'MCI': 1, 'AD': 2}\n",
    "BINARY_LABELS = {'CN': 0, 'AD': 1}\n",
    "\n",
    "# shape of the images, both 3D and 2D\n",
    "IMG_SHAPE = (78, 110, 86)\n",
    "IMG_2D_SHAPE = (IMG_SHAPE[1] * 4, IMG_SHAPE[2] * 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOy42XbKL86G"
   },
   "source": [
    "\n",
    "Define the percentage of the data that are going to be used as a test and validation set. When using TFRecords, data has to be separated in different files, because they cannot be splitted later in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IH4DDrdL-IR"
   },
   "outputs": [],
   "source": [
    "TEST_SPLIT = 0.15\n",
    "VALIDATION_SPLIT = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjuYoxZKMGJD"
   },
   "source": [
    "### Train/Test supervised data split\n",
    "\n",
    "Load the path of every file in a list, and then split the list so the references of training, validation and test data are separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAZi2sReMAX6"
   },
   "outputs": [],
   "source": [
    "# array for saving the filenames\n",
    "filenames = np.array([])\n",
    "\n",
    "# iterate all three class folders in the db\n",
    "for subf in CLASS_SUBFOLDERS:\n",
    "  # using the skull stripped data\n",
    "  path = DB_SS_PATH + subf\n",
    "  for name in os.listdir(path):\n",
    "    complete_name = os.path.join(path, name)\n",
    "    if os.path.isfile(complete_name):\n",
    "      filenames = np.concatenate((filenames, complete_name), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6ZWTB4ZNKHE",
    "outputId": "2690f118-8a6a-44e1-e9b3-17dea7cae23b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2294,)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzyevFMYNqxu",
    "outputId": "5605119d-3a5d-4181-e1b2-4faf06be67cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (1658,)\n",
      "Validation set: (292,)\n",
      "Test set: (344,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "  np.random.shuffle(filenames)\n",
    "  \n",
    "test_margin = int(len(filenames) * TEST_SPLIT)\n",
    "training_set, test_set = filenames[test_margin:], filenames[:test_margin]\n",
    "\n",
    "validation_margin = int(len(training_set) * VALIDATION_SPLIT)\n",
    "training_set, validation_set = training_set[validation_margin:], training_set[:validation_margin]\n",
    "\n",
    "print('Training set:', training_set.shape)\n",
    "print('Validation set:', validation_set.shape)\n",
    "print('Test set:', test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKcQtXteOUy2"
   },
   "source": [
    "\n",
    "### 3D TFRecords database for supervised learning\n",
    "\n",
    "Let´s build the 3D TFRecords database for supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2rnYvk7OYV_"
   },
   "source": [
    "Load the data description file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "LZwofGEbOIyh",
    "outputId": "ce91c55a-ac8f-4420-da8e-424c1b3341dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I97341</td>\n",
       "      <td>941_S_1311</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>9/27/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>6/05/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I97327</td>\n",
       "      <td>941_S_1311</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>3/02/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>6/05/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I112538</td>\n",
       "      <td>941_S_1311</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>6/01/2008</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>6/05/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I75150</td>\n",
       "      <td>941_S_1202</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>8/24/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>6/04/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I63874</td>\n",
       "      <td>941_S_1202</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>1/30/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>6/04/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image Data ID     Subject Group Sex  ...       Type   Acq Date Format Downloaded\n",
       "0        I97341  941_S_1311   MCI   M  ...  Processed  9/27/2007  NiFTI  6/05/2021\n",
       "1        I97327  941_S_1311   MCI   M  ...  Processed  3/02/2007  NiFTI  6/05/2021\n",
       "2       I112538  941_S_1311   MCI   M  ...  Processed  6/01/2008  NiFTI  6/05/2021\n",
       "3        I75150  941_S_1202    CN   M  ...  Processed  8/24/2007  NiFTI  6/04/2021\n",
       "4        I63874  941_S_1202    CN   M  ...  Processed  1/30/2007  NiFTI  6/04/2021\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = pd.read_csv(DESCRIPTION_FILE)\n",
    "description.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrqbXxw3Oo7R"
   },
   "source": [
    "Now, design a method that loads a 3D `.nii` image and some of its information. Taking the absolute path, split the name by directories to get the image name. With that, obtain the class label. Also, obtain the subject ID from the image file name. Finally, read the image using `SimpleITK`, transform into a `numpy` array and return the image, the label and the subject ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UU9S9knaOdRE"
   },
   "outputs": [],
   "source": [
    "def load_image_3D(abs_path):\n",
    "  ''' Load an image (.nii) and its label, from its absolute path.\n",
    "      \n",
    "      Parameters:\n",
    "        abs_path -- Absolute path, filename included\n",
    "        \n",
    "      Returns:\n",
    "        img -- The .nii image, converted into a numpy array\n",
    "        label -- The label of the image\n",
    "        \n",
    "  '''\n",
    "  \n",
    "  # obtain the label from the path (it is the last directory name)\n",
    "  split_path = abs_path.split('/')\n",
    "  label = LABELS[split_path[-2]]\n",
    "  \n",
    "  # obtain the ID of the subject\n",
    "  img_name = split_path[-1]\n",
    "  subject = '_'.join(img_name.split('_')[1:4])\n",
    "  \n",
    "  # load the image with SimpleITK\n",
    "  sitk_image = sitk.ReadImage(abs_path)\n",
    "  \n",
    "  # transform into a numpy array\n",
    "  img = sitk.GetArrayFromImage(sitk_image)\n",
    "  \n",
    "  return img, label, subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apZ0CPR1QOBz"
   },
   "source": [
    "Now, create a new method for creating `.tfrecords` files. It would be necessary to specifiy the filenames of all the images that are going to be stored in the `.tfrecords`, as well as the name for this file.\n",
    "In the method, several extra data, besides the image and label, are stored for each example (subject, age, sex, preprocessing and image ID). This was stored just in case these data were needed in forward steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2pwcXOpP2Bp"
   },
   "outputs": [],
   "source": [
    "def create_tf_record(img_filenames, tf_rec_filename):\n",
    "  ''' Create a TFRecord file, including the information\n",
    "      of the specified images\n",
    "      \n",
    "      Parameters:\n",
    "        img_filenames -- Array with the path to every\n",
    "                         image that is going to be included\n",
    "                         in the TFRecords file.\n",
    "        tf_rec_filename -- Name of the TFRecords file.\n",
    "  '''\n",
    "  \n",
    "  # open the file\n",
    "  writer = tf.io.TFRecordWriter(tf_rec_filename)\n",
    "  \n",
    "  # iterate through all .nii files\n",
    "  for meta_data in img_filenames:\n",
    "\n",
    "    # load the image and label\n",
    "    img, label, subject = load_image_3D(meta_data)\n",
    "    \n",
    "    # also save the preprocessing information and the subject age and sex\n",
    "    meta_data_split = meta_data.split('/')\n",
    "    filename_split = meta_data_split[-1].split('_')\n",
    "    \n",
    "    # save the preprocessing technique used\n",
    "    preprocessing = '_'.join(filename_split[5:-3])\n",
    "    \n",
    "    # get the image ID\n",
    "    if filename_split[-1].endswith('.gz'): image_ID = int(filename_split[-1][1:-7])\n",
    "    else: image_ID = int(filename_split[-1][1:-4])\n",
    "      \n",
    "    # get the age and sex of the subject\n",
    "    age_and_sex = description.loc[description['Image Data ID'] == image_ID, ['Age', 'Sex']].iloc[0]\n",
    "    \n",
    "    # create a feature\n",
    "    feature = {'label': _int64_feature(label),\n",
    "               'subject': _bytes_feature(subject.encode('utf-8')),\n",
    "               'preprocessing': _bytes_feature(preprocessing.encode('utf-8')),\n",
    "               'subject_age': _int64_feature(age_and_sex[0]),\n",
    "               'subject_sex': _bytes_feature(age_and_sex[1].encode('utf-8')),\n",
    "               'image_id': _int64_feature(image_ID),\n",
    "               'image': _float_feature(img.ravel())}\n",
    "\n",
    "    # create an example protocol buffer\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "    # serialize to string and write on the file\n",
    "    writer.write(example.SerializeToString())\n",
    "    \n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NABotCq3QCIj"
   },
   "source": [
    "Define the complete path names for the `.tfrecords` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3HydW3XQCtr"
   },
   "outputs": [],
   "source": [
    "train_tfrec = os.path.join(DB_TF_3D_PATH, TFREC_3D_SS_TRAIN)\n",
    "test_tfrec = os.path.join(DB_TF_3D_PATH, TFREC_3D_SS_TEST)\n",
    "val_tfrec = os.path.join(DB_TF_3D_PATH, TFREC_3D_SS_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4Vj2U3krX6M"
   },
   "outputs": [],
   "source": [
    "create_tf_record(training_set, train_tfrec)\n",
    "reate_tf_record(test_set, test_tfrec)\n",
    "create_tf_record(validation_set, val_tfrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9UuQQuAX4gZd",
    "outputId": "ccac2fea-e7e2-4bae-8c06-fee80789660a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/TF_RECORDS/TF_RECORDS_3D/train.3D.skull_stripped.tfrecords'"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfrec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQO_SKpbJhAR",
    "outputId": "fef6bc65-bec3-4660-d9ea-f69d91dd5b0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/content/drive/MyDrive/SKULL_STRIPPED/CN/ADNI_062_S_0578_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070424114540207_S15035_I50459.nii.gz',\n",
       "       '/content/drive/MyDrive/SKULL_STRIPPED/MCI/ADNI_018_S_0080_MR_MPR____N3__Scaled_Br_20070821181307557_S24963_I69594.nii.gz',\n",
       "       '/content/drive/MyDrive/SKULL_STRIPPED/AD/ADNI_023_S_0916_MR_MPR__GradWarp__B1_Correction__N3__Scaled_2_Br_20081001154612955_S30418_I118884.nii.gz',\n",
       "       ...,\n",
       "       '/content/drive/MyDrive/SKULL_STRIPPED/AD/ADNI_082_S_1377_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20071101192159389_S40021_I80388.nii.gz',\n",
       "       '/content/drive/MyDrive/SKULL_STRIPPED/AD/ADNI_012_S_0689_MR_MPR____N3__Scaled_2_Br_20081001125017695_S24938_I118740.nii.gz',\n",
       "       '/content/drive/MyDrive/SKULL_STRIPPED/AD/ADNI_029_S_0999_MR_MPR-R__GradWarp__B1_Correction__N3__Scaled_Br_20070805144703422_S23248_I64898.nii.gz'],\n",
       "      dtype='<U148')"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb5oBcwIt4_S"
   },
   "source": [
    "### 2D TFRecords database for supervised learning\n",
    "\n",
    "Let´s build the 2D TFRecords database for supervised learning. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6wS5pUXt_jW"
   },
   "source": [
    "In this case, images need to be transformed to 2D. The following method does exactly that, taking multiple horizontal slices and putting them in a 2D matrix. In the final version, 16 slices were used. Some considerations:\n",
    "\n",
    "* The top slice was selected manually, after some tests. Higher cuts did not show any useful information.\n",
    "* The same for the bottom slice. Below slices only showed some of the brainstem. \n",
    "* If 16 cuts were wanted, every two slices from 30 to 60 has to be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML2S7Wh1PTO3"
   },
   "outputs": [],
   "source": [
    "def slices_matrix_2D(img):\n",
    "  ''' Transform a 3D MRI image into a 2D image, by obtaining 9 slices \n",
    "      and placing them in a 4x4 two-dimensional grid.\n",
    "      \n",
    "      All 16 cuts are from a horizontal/axial view. They are selected\n",
    "      from the 30th to the 60th level of the original 3D image.\n",
    "      \n",
    "      Parameters:\n",
    "        img -- np.ndarray with the 3D image\n",
    "        \n",
    "      Returns:\n",
    "        np.ndarray -- The resulting 2D image\n",
    "  '''\n",
    "  \n",
    "  # create the final 2D image \n",
    "  image_2D = np.empty(IMG_2D_SHAPE)\n",
    "  \n",
    "  # set the limits and the step\n",
    "  TOP = 60\n",
    "  BOTTOM = 30\n",
    "  STEP = 2\n",
    "  N_CUTS = 16\n",
    "  \n",
    "  # iterator for the cuts\n",
    "  cut_it = TOP\n",
    "  # iterator for the rows of the 2D final image\n",
    "  row_it = 0\n",
    "  # iterator for the columns of the 2D final image\n",
    "  col_it = 0\n",
    "  \n",
    "  for cutting_time in range(N_CUTS):\n",
    "    \n",
    "    # cut\n",
    "    cut = img[cut_it, :, :]\n",
    "    cut_it -= STEP\n",
    "    \n",
    "    # reset the row iterator and move the\n",
    "    # col iterator when needed\n",
    "    if cutting_time in [4, 8, 12]:\n",
    "      row_it = 0\n",
    "      col_it += cut.shape[1]\n",
    "    \n",
    "    # copy the cut to the 2D image\n",
    "    for i in range(cut.shape[0]):\n",
    "      for j in range(cut.shape[1]):\n",
    "        image_2D[i + row_it, j + col_it] = cut[i, j]\n",
    "    row_it += cut.shape[0]\n",
    "  \n",
    "  # return the final 2D image, with 3 channels\n",
    "  # this is necessary for working with most pre-trained nets\n",
    "  return np.repeat(image_2D[None, ...], 3, axis=0).T\n",
    "  #return image_2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtJOm8XGuJj0"
   },
   "source": [
    "The following method uses the previous 2D transformation to load the 3D images from disk and transforms them. Also returns the image label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bj5zwkbcuFPn"
   },
   "outputs": [],
   "source": [
    "def load_image_2D(abs_path, labels):\n",
    "  ''' Load an image (.nii) and its label, from its absolute path.\n",
    "      Transform it into a 2D image, by obtaining 16 slices and placing them\n",
    "      in a 4x4 two-dimensional grid.\n",
    "      \n",
    "      Parameters:\n",
    "        abs_path -- Absolute path, filename included\n",
    "        labels -- Label mapper\n",
    "        \n",
    "      Returns:\n",
    "        img -- The .nii image, converted into a numpy array\n",
    "        label -- The label of the image (from argument 'labels')\n",
    "        \n",
    "  '''\n",
    "  \n",
    "  # obtain the label from the path (it is the last directory name)\n",
    "  label = labels[abs_path.split('/')[-2]]\n",
    "  \n",
    "  # load the image with SimpleITK\n",
    "  sitk_image = sitk.ReadImage(abs_path)\n",
    "  \n",
    "  # transform into a numpy array\n",
    "  img = sitk.GetArrayFromImage(sitk_image)\n",
    "  \n",
    "  # apply whitening\n",
    "  img = preprocessing.whitening(img)\n",
    "  \n",
    "  # make the 2D image\n",
    "  img = slices_matrix_2D(img)\n",
    "  \n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeJAJNy7uS-j"
   },
   "outputs": [],
   "source": [
    "train_tfrec2D = os.path.join(DB_TF_2D_PATH, TFREC_2D_SS_TRAIN)\n",
    "test_tfrec2D = os.path.join(DB_TF_2D_PATH, TFREC_2D_SS_TEST)\n",
    "val_tfrec2D = os.path.join(DB_TF_2D_PATH, TFREC_2D_SS_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaaOm7KjuWF1"
   },
   "outputs": [],
   "source": [
    "def create_tf_record_2D(img_filenames, tf_rec_filename, labels):\n",
    "  ''' Create a TFRecord file, including the information\n",
    "      of the specified images, after converting them into \n",
    "      a 2D grid.\n",
    "      \n",
    "      Parameters:\n",
    "        img_filenames -- Array with the path to every\n",
    "                         image that is going to be included\n",
    "                         in the TFRecords file.\n",
    "        tf_rec_filename -- Name of the TFRecords file.\n",
    "        labels -- Label mapper\n",
    "  '''\n",
    "  \n",
    "  # open the file\n",
    "  writer = tf.io.TFRecordWriter(tf_rec_filename)\n",
    "  \n",
    "  # iterate through all .nii files\n",
    "  for meta_data in img_filenames:\n",
    "\n",
    "    # load the image and label\n",
    "    img, label = load_image_2D(meta_data, labels)\n",
    "\n",
    "    # create a feature\n",
    "    feature = {'label': _int64_feature(label),\n",
    "               'image': _float_feature(img.ravel())}\n",
    "\n",
    "    # create an example protocol buffer\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "    # serialize to string and write on the file\n",
    "    writer.write(example.SerializeToString())\n",
    "    \n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vy2_vhHCuaVv"
   },
   "outputs": [],
   "source": [
    "create_tf_record_2D(training_set, train_tfrec2D, LABELS)\n",
    "create_tf_record_2D(test_set, test_tfrec2D, LABELS)\n",
    "create_tf_record_2D(validation_set, val_tfrec2D, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AW33xoyr1SC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TFrecords",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
